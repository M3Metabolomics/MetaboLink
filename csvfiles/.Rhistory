runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
for (i in 1:10) {
print(i)
}
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
library(ggplot2)
library(plotly)
library(caret)
library(clusterProfiler)
library(org.Hs.eg.db)
library(webchem)
library(dplyr)
library(rJava)
library(rJava)
Sys.setenv(JAVA_HOME='~/Library/Internet Plug-Ins')
library(rJava)
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
if(colnames(main_df) != rownames(identifier_df)) {
stop("The rownames and colnames of the two data frames do not match. Please check the data.")
}
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
shiny::runApp('Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
#### Testing data ----
setwd("~/Desktop/SDU/Cand/Master thesis /Datasets/PP/OneDrive_1_9-25-2024")
pos <- read.csv("PPP pos1.csv", header = TRUE, sep = ",")
data_subset <- subset_data(pos, "compound")
#---------------------------------------------------------#
#                   GO TERM ANALYSIS                      #
#---------------------------------------------------------#
# Load libraries
library(webchem)
library(tibble)
# library(dplyr)
# library(rJava)
# library(rcdk)
# library(KEGGREST)
# Function to subset data based on some criteria in the identifier column
is_valid <- function(x) {
!(is.na(x) | x == "" | x == " " | x == "N/A" | x == "NA")
}
subset_data <- function(data, compound_column) {
# Keep rows where either the identifier_column OR the compound_column is valid ie. not missing
subset <- data[ is_valid(data[[compound_column]]), ]
cat("The number of rows and columns in the data are:", nrow(subset), "and", ncol(subset), "\n")
return(subset)
}
# THE NEXT SECTION CAN BE DELETED AS IT HAS BEEN UPDATED
# # Main function to gather identifiers
# gather_identifiers <- function(data, identifier_column) {
#   # Initialize the results df
#   identifier_df <- data.frame()
#   # Use a progress bar to track progress
#   shiny::withProgress(message = "Gathering identifiers...", value = 0, {
#     for (i in 1:nrow(data)) { # nrow(data) instead of 2
#       # Increment the progress bar
#       incProgress(1 / nrow(data), detail = paste("Processing metabolite", i, "of", nrow(data)))
#
#       # Get the start time
#       start <- Sys.time()
#       # Get the InChI from the data and other identifiers using webchem
#       InChI <- data[[identifier_column]][i]
#       # InChIKey <- tryCatch(cs_convert(InChI, from = "inchi", to = "inchikey"), error = function(e) NA)
#       # SMILES <- tryCatch(cs_convert(InChI, from = "inchi", to = "smiles"), error = function(e) NA)
#       CID <- tryCatch(get_cid(InChI, from = "inchi") %>% slice(1) %>% pull(cid), error = function(e) NA)
#       # CSID <- tryCatch(get_csid(InChI, from = "inchi") %>% pull(csid), error = function(e) NA)
#       IUPACName <- tryCatch(pc_prop(as.integer(CID)) %>% slice(1) %>% pull(IUPACName), error = function(e) NA)
#       WDID <- tryCatch(pc_sect(CID, "wikidata")%>% slice(1) %>% pull(SourceID), error = function(e) NA)
#       HMDBID <- tryCatch(pc_sect(CID, "hmdb id")%>% slice(1) %>% pull(Result), error = function(e) NA)
#       CASID <- tryCatch(pc_sect(CID, "cas")%>% slice(1) %>% pull(Result), error = function(e) NA)
#       KEGGID <- tryCatch(pc_sect(CID, "kegg id")%>% slice(1) %>% pull(Result), error = function(e) NA)
#       ChEBIID <- tryCatch(get_chebiid(InChI, from = "inchi")%>% slice(1) %>% pull(chebiid), error = function(e) NA)
#
#       # Append each row to identifier_df
#       identifier_df <- rbind(identifier_df, data.frame(
#         InChI = InChI,
#         # InChIKey = InChIKey,
#         # SMILES = SMILES,
#         CID = CID,
#         # CSID = CSID,
#         IUPACName = IUPACName,
#         WDID = WDID,
#         HMDBID = HMDBID,
#         CASID = CASID,
#         KEGGID = KEGGID,
#         ChEBIID = ChEBIID,
#         stringsAsFactors = FALSE
#       ))
#
#       # Print runtime for debugging
#       cat("Metabolite:", i, "Run Time:", Sys.time() - start, "seconds\n")
#     }
#   })
#
#   # Return the identifier_df
#   return(identifier_df)
# }
# Function to update InChI in the data frame
update_inchi <- function(data, compound_column, identifier_column, query) {
print(paste0("# of entries: ", nrow(data)))
print(paste0("# of inchi entries in data: ",
sum(!is.na(data[[identifier_column]]) & !data[[identifier_column]] %in% c("", " ", "NA", "N/A"))))
print(paste0("# of missing InChI entries in data: ",
sum(is.na(data[[identifier_column]]) | data[[identifier_column]] %in% c("", " ", "NA", "N/A"))))
# Identify rows with missing or invalid InChI
missing_idx <- which(is.na(data[[identifier_column]]) | data[[identifier_column]] %in% c("", " ", "NA", "N/A"))
if (length(missing_idx) == 0) {
message("No missing InChI entries found.")
return(data)
}
# Create lookup from query (Identifier -> InChI)
inchi_map <- setNames(query$InChI, query$Identifier)
# Update InChI from query
compounds_missing <- data[[compound_column]][missing_idx]
data[[identifier_column]][missing_idx] <- ifelse(
compounds_missing %in% names(inchi_map),
inchi_map[compounds_missing],
data[[identifier_column]][missing_idx]
)
print(paste0("# of inchi entries in data after local update: ",
sum(!is.na(data[[identifier_column]]) & !data[[identifier_column]] %in% c("", " ", "NA", "N/A"))))
print(paste0("# of missing InChI entries in data after local update: ",
sum(is.na(data[[identifier_column]]) | data[[identifier_column]] %in% c("", " ", "NA", "N/A"))))
# Handle still-missing InChI entries using cir_query()
still_missing_idx <- which(is.na(data[[identifier_column]]) | data[[identifier_column]] %in% c("", " ", "NA", "N/A"))
if (length(still_missing_idx) > 0) {
no_inchi_compounds <- unique(data[[compound_column]][still_missing_idx])
message("Fetching InChI using cir_query for: ", paste(no_inchi_compounds, collapse = ", "))
# Replace the following line with your `cir_query()` implementation
inchi_results <- vapply(no_inchi_compounds, function(compound) {
res <- tryCatch({ cir_query(compound, from = "name", to = "inchi") }, error = function(e) NA_character_)
if (length(res) != 1) {
# Handle unexpected length, e.g. take first element or force NA
NA_character_
} else {
as.character(res)
}
}, character(1))
# Update data with fetched InChI
for (i in seq_along(no_inchi_compounds)) {
idx <- which(data[[compound_column]] == no_inchi_compounds[i])
data[[identifier_column]][idx] <- inchi_results[no_inchi_compounds[i]]
}
}
print(sapply(data,function(x) sum(!is.na(x) & x != "" & x != " " & x != "NA" & x != "N/A")))
print(data[[identifier_column]])
print(paste0("# of missing InChI entries in data after online update: ",
sum(is.na(data[[identifier_column]]) | data[[identifier_column]] %in% c("", " ", "NA", "N/A"))))
return(data)
}
# pos1 <- update_inchi(pos, compound_column = "compound", identifier_column = "inchi")
# # pos1 <- update_inchi(pos[1:10, ], compound_column = "compound", identifier_column = "inchi")
# # Investigate pos1 inchi
# sum(is.na(pos1$inchi))
#
# cat("Before: ", "\n")
# cat("Number of features: ", nrow(pos), "\n")
# cat("Number of compounds: ", nrow(pos)-sum(pos$compound == "" | pos$compound == " " | pos$compound == "N/A"), "\n")
# cat("Number of missing compounds: ", sum(pos$compound == "" | pos$compound == " " | pos$compound == "N/A"), "\n")
# cat("Number of InChI: ", nrow(pos)-sum(pos$inchi == "" | pos$inchi == " " | pos$inchi == "N/A"), "\n")
# cat("Number of missing InChI: ", sum(pos$inchi == "" | pos$inchi == " " | pos$inchi == "N/A"), "\n")
# cat("After: ", "\n")
# cat("Number of features: ", nrow(pos1), "\n")
# cat("Number of InChI: ",
#     nrow(pos1)-sum(is.na(pos1$inchi) | pos1$inchi == "" | pos1$inchi == " " | pos1$inchi == "NA"),
#     "\n")
# cat("Number of missing InChI: ",
#     sum(is.na(pos1$inchi) | pos1$inchi == "" | pos1$inchi == " " | pos1$inchi == "NA"),
#     "\n")
#
# # Counts of successes (InChI found) before and after
# counts <- c(120, 399)
# totals <- c(4511, 4511)
#
# # Run a two-proportion test
# test_result <- prop.test(counts, totals)
#
# test_result
# Main function to gather CID's
update_cid <- function(data, identifier_column, query) {
print(paste0("# of entries: ", nrow(data)))
# Start timer for performance monitoring
Start <- Sys.time()
# Ensure identifier_column is a vector
identifiers <- data[[identifier_column]]
if (!is.vector(identifiers)) {
stop("identifier_column must be a vector.")
}
# debuggin:
print(paste0("# of identifiers: ", length(identifiers)))
# Check that 'query' data frame has required columns
required_cols <- c("Identifier", "InChI", "CID")
if (!all(required_cols %in% names(query))) {
stop("The 'query' data frame must contain 'Identifier', 'InChI', and 'CID' columns.")
}
# Initialize a tibble with queries (InChI) and initially unknown CIDs
# Here, 'query' column represents the InChI from data
CIDs <- tibble(query = identifiers, cid = NA_character_)
print(paste0("# of CIDs: ", nrow(CIDs)))
# Function to count missing CIDs
count_missing <- function(x) sum(is.na(x) | x == "" | x == " " | x == "NA" | x == "N/A")
# Print initial missing count
cat("Initial missing CIDs:", count_missing(CIDs$cid), "\n")
# Step 1: Local Update from 'query'
# Create a lookup map from query InChI to CID
cid_map_inchi <- setNames(query$CID, query$InChI)
print(paste0("# of CID map InChI: ", length(cid_map_inchi)))
# Update CIDs where possible from local data using InChI
local_idx <- CIDs$query %in% names(cid_map_inchi)
print(paste0("# of local idx: ", sum(local_idx)))
CIDs$cid[local_idx] <- cid_map_inchi[CIDs$query[local_idx]]
print(paste0("# of CIDs after local update: ", sum(!is.na(CIDs$cid))))
# Print count after local update
cat("After local update missing CIDs:", count_missing(CIDs$cid), "\n")
# Check if all missing CIDs are resolved
still_missing_idx <- which(is.na(CIDs$cid) | CIDs$cid %in% c("", " ", "NA", "N/A"))
print(paste0("# of still missing idx: ", length(still_missing_idx)))
if (length(still_missing_idx) == 0) {
cat("All missing CIDs updated from local cache.\n")
cat("Run Time CID collection:", Sys.time() - Start, "min\n")
merged_data <- merge_data(data, CIDs, identifier_column)
return(merged_data)
}
# Step 2: Online Lookup for Remaining Missing CIDs
# For each missing InChI, attempt to retrieve CID online
for (i in still_missing_idx) {
input_for_cid <- CIDs$query[i]  # This is the InChI
print(paste0("Input for CID: ", input_for_cid))
# Attempt to retrieve CID from online service
res <- tryCatch({
get_cid(input_for_cid, from = "inchi")
}, error = function(e) {
NULL
})
if (!is.null(res) && "cid" %in% names(res) && !is.na(res$cid)) {
CIDs$cid[i] <- res$cid
} else {
# Remains NA if we cannot retrieve CID
CIDs$cid[i] <- NA
}
}
# Print final missing count after online update
cat("After online update missing CIDs:", count_missing(CIDs$cid), "\n")
# Check if some remain missing
final_missing <- which(is.na(CIDs$cid) | CIDs$cid %in% c("", " ", "NA", "N/A"))
if (length(final_missing) > 0) {
warning("No CID found for some queries even after online lookup: ",
paste(CIDs$query[final_missing], collapse = ", "))
}
#remove duplicates from CIDs
CIDs <- CIDs[!duplicated(CIDs$cid), ]
# use the merge_data function to merge data with the CID
merged_data <- merge_data(data, CIDs, identifier_column)
# Print run time
cat("Run Time CID collection:", Sys.time() - Start, "min\n")
return(merged_data)
}
# Function to merge data based on the identifier column
merge_data <- function(main_df, identifier_df, identifier_column) {
# Ensure the identifier column has the same name in both data frames
names(identifier_df)[1] <- identifier_column
# Identify overlapping columns other than the identifier_column
common_cols <- intersect(names(main_df), names(identifier_df))
common_cols <- setdiff(common_cols, identifier_column)
# Rename overlapping columns in identifier_df to avoid duplication
if(length(common_cols) > 0) {
names(identifier_df)[names(identifier_df) %in% common_cols] <- paste0(common_cols, "_id")
}
# Debugging
# print(head(identifier_df))
# print(dim(identifier_df))
# print(head(main_df[[identifier_column]]))
# print(dim(main_df))
# Merge main_df and identifier_df on the identifier column
merged_df <- merge(main_df, identifier_df, by = identifier_column, all.x = TRUE)
# Get the position of the identifier_column in main_df
identifier_index <- which(names(main_df) == identifier_column)
# Get the names of the columns from identifier_df (excluding identifier_column)
id_cols <- setdiff(names(identifier_df), identifier_column)
# Build the new column order
# Start with columns before the identifier_column in main_df
if(identifier_index > 1) {
left_cols <- names(main_df)[1:(identifier_index - 1)]
} else {
left_cols <- character(0)
}
# Columns after the identifier_column in main_df
if(identifier_index < ncol(main_df)) {
right_cols <- names(main_df)[(identifier_index + 1):ncol(main_df)]
} else {
right_cols <- character(0)
}
# New column order: left_cols, identifier_column, id_cols (from identifier_df), right_cols
new_col_order <- c(left_cols, identifier_column, id_cols, right_cols)
# Reorder the merged_df according to new_col_order
final_df <- merged_df[, new_col_order]
return(final_df)
}
# cleaning names function ----
clean_compound_names <- function(names_vec) {
sapply(names_vec, function(x) {
# If there's a semicolon, take only the part before the first semicolon
if (grepl(";", x)) {
x <- strsplit(x, ";", fixed = TRUE)[[1]][1]
}
x <- trimws(x)
# If there's a comma, take only the part before the first comma
if (grepl(", ", x)) {
x <- strsplit(x, ", ", fixed = TRUE)[[1]][1]
}
x <- trimws(x)
# Remove " cation" and " anion" from the end of the name
x <- gsub(" cation$", "", x)
x <- gsub(" anion$", "", x)
x <- trimws(x)
# Remove " - [0-9.]+ eV" from the end of the name
x <- gsub(" - [0-9.]+ eV$", "", x)
x <- trimws(x)
return(x)
}, USE.NAMES = FALSE)
}
remove_top_level_comma <- function(s) {
chars <- strsplit(s, "")[[1]]
depth <- 0
comma_pos <- NA
for (i in seq_along(chars)) {
c <- chars[i]
if (c == "(") {
depth <- depth + 1
} else if (c == ")") {
depth <- depth - 1
} else if (c == "," && depth == 0) {
# Found a comma at top-level (not inside parentheses)
comma_pos <- i
break
}
}
if (!is.na(comma_pos)) {
# Keep only the part before the top-level comma
s <- substr(s, 1, comma_pos - 1)
}
s <- trimws(s)
return(s)
}
# insert column ----
# Make a function that take in a df and a column name and insert a new column to the right of the column
insertColumn <- function(df, column_name, new_column_name, new_column) {
# Get the position of the column
column_position <- which(names(df) == column_name)
if (length(column_position) == 0) {
stop("Column not found")
}
# Check if new column has the correct length
if (length(new_column) != nrow(df)) {
stop("The new column must have the same number of rows as the data frame")
}
# Split the data frame into two parts
left_df <- df[, 1:column_position, drop = FALSE]
right_df <- df[, (column_position + 1):ncol(df), drop = FALSE]
# Insert the new column as a data frame
new_col_df <- data.frame(new_column)
names(new_col_df) <- new_column_name
# Combine the data frames
new_df <- cbind(left_df, new_col_df, right_df)
return(new_df)
}
# Function to perform pathway enrichment analysis
data_subset <- subset_data(pos, "compound")
desired_properties <- c(
"MolecularFormula", "MolecularWeight", "ExactMass", "MonoisotopicMass",
"CanonicalSMILES", "IsomericSMILES", "InChI", "InChIKey", "IUPACName"
)
all_results <- data.frame()
chunk_size <- 5
# Identify new compounds (those not already in query$Identifier)
new_compounds <- data_subset[["compound"]][!data_subset[["compound"]] %in% query$Identifier]
setwd("~/Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main/csvfiles")
query <- read.csv("queried_properties.csv", header = TRUE, sep = ",") # new copy
# Identify new compounds (those not already in query$Identifier)
new_compounds <- data_subset[["compound"]][!data_subset[["compound"]] %in% query$Identifier]
new_compounds <- unique(new_compounds)
if (length(new_compounds) > 0) {
num_rows <- length(new_compounds)
print(paste("Number of rows/elements in new_compounds for querying:", num_rows))
row_indices <- seq(1, num_rows, by = chunk_size)
print("Row indices to be processed:")
print(row_indices)
for (start_idx in row_indices) {
end_idx <- min(start_idx + chunk_size - 1, num_rows)
print(paste("Processing rows from", start_idx, "to", end_idx))
compound_subset <- new_compounds[start_idx:end_idx]
print("Current compound subset:")
print(compound_subset)
props_chunk <- tryCatch({
get_properties(
properties = desired_properties,
identifier = compound_subset,
namespace = "name",
propertyMatch = list(.ignore.case = TRUE, type = "contain")
)
}, error = function(e) {
warning("Failed to get properties for compounds: ", paste(compound_subset, collapse = ", "))
return(NULL)
})
if (is.null(props_chunk) || !inherits(props_chunk, "PubChemInstanceList")) {
print("props_chunk is NULL or not a PubChemInstanceList, skipping this batch.")
Sys.sleep(1) # respect rate limit
next
}
props_retrieved <- tryCatch({
retrieve(object = props_chunk, .to.data.frame = TRUE, .combine.all = TRUE)
}, error = function(e) {
warning("Failed to retrieve data for compounds: ", paste(compound_subset, collapse = ", "))
return(data.frame())
})
if (!is.null(props_retrieved) && nrow(props_retrieved) > 0) {
all_results <- dplyr::bind_rows(all_results, props_retrieved)
} else {
print("No valid rows retrieved for this batch.")
}
print(Sys.time())
# Pause to respect the 5 queries/second limit
Sys.sleep(1)
}
if (nrow(all_results) > 0) {
# Convert these columns to numeric if they aren't already
all_results$MolecularWeight <- as.numeric(all_results$MolecularWeight)
all_results$ExactMass <- as.numeric(all_results$ExactMass)
all_results$MonoisotopicMass <- as.numeric(all_results$MonoisotopicMass)
dir_path <- "~/Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main/csvfiles" # Adjust path as needed
file_path <- file.path(dir_path, "queried_properties.csv")
# If the file already exists, read it and combine
if (file.exists(file_path)) {
existing_data <- read.csv(file_path, stringsAsFactors = FALSE)
# Identify new entries that are not already in existing_data by 'Identifier'
if ("Identifier" %in% colnames(existing_data) && "Identifier" %in% colnames(all_results)) {
new_entries <- dplyr::anti_join(all_results, existing_data, by = "Identifier")
query_final <- nrow(new_entries)
print(paste("Number of rows in query after gathering identifiers:", query_final))
} else {
# If 'Identifier' is not present, just append all results
warning("No 'Identifier' column found. Appending all results without filtering.")
new_entries <- all_results
}
# Only bind if there are new entries
if (nrow(new_entries) > 0) {
combined_data <- dplyr::bind_rows(existing_data, new_entries)
# Remove duplicates based on Identifier if needed
combined_data <- combined_data[!duplicated(combined_data$Identifier), ]
combined_data_nrow <- nrow(combined_data)
print(paste("Number of rows in query after gathering identifiers:", combined_data_nrow))
write.csv(combined_data, file_path, row.names = FALSE)
message("queried_properties.csv has been updated with new entries.")
} else {
message("No genuinely new entries to add. The existing queried_properties.csv remains unchanged.")
}
} else {
# No existing file, just create a new one
write.csv(all_results, file_path, row.names = FALSE)
message("queried_properties.csv has been created with the new entries.")
}
} else {
message("No results retrieved for these new compounds.")
}
} else {
message("No new compounds found to query.")
}
data_subset_inchi <- update_inchi(data_subset, "compound", "inchi", query)
print(head(data_subset_inchi))
dim(data_subset_inchi)
data_subset_inchi_cid <- update_cid(data_subset_inchi, "inchi", query)
pubchemInchi2cid(pos$inchi[1:10])
library(ChemmineR)
pubchemInchi2cid(pos$inchi[1:10])
View(pos)
pubchemInchi2cid(pos$inchi)
runApp('~/Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
runApp('~/Desktop/SDU/Cand/Master thesis /GitHub/MetaboLink-Main')
